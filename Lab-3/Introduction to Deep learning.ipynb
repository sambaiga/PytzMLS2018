{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PytzMLS2018:  Lab 3: Introduction to deep learning\n",
    "\n",
    "<center>**Anthony Faustine (sambaiga@gmail.com)**</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary libries and modules we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from ploting import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Feed-forward Neural Network\n",
    "\n",
    "**Learning goal**: How to implement a feed-forward neural network by using PyTorch. In this lab we will train a feed-forward neural network by using PyTorch. We will do the following steps in order:\n",
    "\n",
    "**Task**: Build MLP classifier to recognize handwritten digits using the MNIST dataset. MNIST contains 70,000 images: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels, and centered to reduce preprocessing and get started quicker. \n",
    "\n",
    "** Procedure**\n",
    "\n",
    "1. Load the training and test datasets using DataLoader\n",
    "2. Define a Feedforwad Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load dataset\n",
    "\n",
    "We will use DataLoader and TensorDataset (from torch.utils.data) for convinience in data handling. You can create your custom dataset class by inheriting Dataset with some required member functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='../data/mnist', \n",
    "                            train=True, # this is training data\n",
    "                            transform=transforms.ToTensor(),# Converts a PIL.Image or numpy.ndarray to\n",
    "                                                           # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../data/mnist', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Make iteratable data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2  Visualize train dataset\n",
    "\n",
    "\n",
    "Let's inspect a few examples. The MNIST dataset contains only grayscale images. For more advanced datasets, we'll have the three color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=6)\n",
    "fig, axs = plt.subplots(2,5, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.25, wspace=.1)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axs[i].imshow(train_dataset.train_data[i].numpy(), cmap='gray', interpolation='none')\n",
    "    axs[i].set_title('%i' % train_dataset.train_labels[i], fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define  MLP model\n",
    "\n",
    "In this step we define MLP model. For simplicity, we will use 3-layer MLP in which each layer is a fully-connected layer and apply RELU activation for each layer with exception to the output layer. \n",
    "\n",
    "**Questions**\n",
    "1. Why can't we apply RelU activation function to the output layer?\n",
    "2. Which output activation function is appropriate for this type of problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(input_dim, hidden_dim, output_dim):\n",
    "    \n",
    "    \n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(input_dim,hidden_dim), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_dim,hidden_dim), \n",
    "    torch.nn.ReLU(),\n",
    "    nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784 #28X28\n",
    "hidden_dim = 16\n",
    "output_dim = 10\n",
    "\n",
    "\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Define a Loss function and OptimizerÂ¶\n",
    "\n",
    "Since this is multi-class classification we will use **Cross Entropy loss**. PyTorch provide **Cross Entropy loss**  loss function which combines a softmax layer and the **Cross Entropy loss** together and it is more numerically stable than using them separately. Thus it is why we didnt  apply softmax activation after the output layer while defining MLP model. See the last model definition above.\n",
    "\n",
    "We will use SGD with momentum as our optimizer. When we create an optimizer in PyTorch, we need to pass parameters that we want to optimize (train) as input arguments. We can retrieve all trainable parameters of the model by calling **model.parameters()**.\n",
    "\n",
    "**Questions**\n",
    "1. Write an expression of a softmax function.\n",
    "2. What are the advantage of using SGD with momentum in training neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "device = torch.device(\"cuda:{0}\".format(args.cuda_num) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Train the network\n",
    "Now, we need to train the model. For each full coverage of train dataset, we just need to do a forward pass computation with a mini-batch of dataset and a backward pass to compute gradients followed by a step of optimization. We need to do this for a reasonable number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, num_epochs, device):\n",
    "    \n",
    "    \n",
    "    total_loss = []\n",
    "    print(\"Start training\")\n",
    "    model=model.to(device)\n",
    "    criterion=criterion.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        training_loss = []\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            labels = labels\n",
    "        \n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model(images)\n",
    "        \n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            training_loss.append(loss.item())\n",
    "        \n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "            # print statistics\n",
    "            # print statistics\n",
    "           \n",
    "            if i %4000 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                epoch+1, i * len(images), len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), np.mean(training_loss)))\n",
    "             \n",
    "              \n",
    "        total_loss.append(np.mean(training_loss))     \n",
    "        \n",
    "       \n",
    "    return total_loss    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models\n",
    "total_loss = train(model,optimizer, criterion, 10, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=4)\n",
    "plt.plot(total_loss, label=\"rate={}\".format(learning_rate))\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device):\n",
    "    \n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    predictions=[]\n",
    "    ground_t=[]\n",
    "    \n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get predictions from the maximum value\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        predictions  += pred.numpy().tolist()\n",
    "        ground_t+= labels.data.numpy().tolist()\n",
    "        #correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        correct += torch.sum(pred == labels.data)\n",
    "    \n",
    "    print('')\n",
    "    predictions = np.array(predictions)\n",
    "    ground_t    = np.array(ground_t)   \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        \n",
    "    print(\"Accuracy: {}%\".format(accuracy))\n",
    "    \n",
    "    return ground_t, predictions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_t, predictions = test(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 VIsualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_indices = np.nonzero(predictions == ground_t)[0]\n",
    "incorrect_indices = np.nonzero(predictions != ground_t)[0]\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1.1 Visualize correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=8)\n",
    "indices = np.random.permutation(correct_indices)\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(test_dataset.test_data[correct].numpy(),  cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Actual {}\".format(predictions[correct], ground_t[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1.2 Visualize incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=8)\n",
    "indices = np.random.permutation(incorrect_indices)\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(test_dataset.test_data[correct].numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Actual {}\".format(predictions[correct], ground_t[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Experiment with other classification metrics implemented in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix**\n",
    "\n",
    "A confusion matrix is a technique for summarizing the performance of a classification algorithm. It is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
    "\n",
    "Classification accuracy alone can be misleading if you have an unequal number of observations in each class or if you have more than two classes in your dataset.\n",
    "\n",
    "Calculating a confusion matrix can give you a better idea of what your classification model is getting right and what types of errors it is making.\n",
    "\n",
    "For detail on confusion matrix refer [here](https://machinelearningmastery.com/confusion-matrix-machine-learning/) and [here](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
    "\n",
    "We use [sklearn library](http://scikit-learn.org/stable/) to calculate confusion matrix and [searborn library](https://seaborn.pydata.org/) to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  confusion_matrix\n",
    "cm=confusion_matrix(ground_t, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class in digits from 0 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.unique(ground_t)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "def confusion_matrix_plot(cm, class_names):\n",
    "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    try:\n",
    "        heatmap = sn.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "        \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=4)\n",
    "confusion_matrix_plot(cm, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 [** Recall, Precision and F-measure**](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)\n",
    "\n",
    "**Recall (Sensitivity)**: is the ratio of correctly predicted positive observations to the all observations in actual class. \n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**Precision**  is the ratio of correctly predicted positive observations to the total predicted positive observations. \n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**F1 score**: is the weighted average of Precision and Recall, it takes both false positives and false negatives into account.\n",
    "\n",
    "$$F1 Score = \\frac{2\\cdot Recall \\cdot Precision} {Recall + Precision}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recal = recall_score(ground_t, predictions, average='weighted')\n",
    "prec  = precision_score(ground_t, predictions, average='weighted')\n",
    "f1    = f1_score(ground_t, predictions, average='weighted')\n",
    "print(\"Recall: {0:.4f}, Precision: {1:.4f}, F-score: {2:.4f}\".format(recal,prec, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Weight Initilization \n",
    "\n",
    "Before  training neural network we have to initialize its parameters. By default pytorch itinilize this parameters for you. However you can use different techniques such as gausian random initilization, kaiming and xavier initialization. In this part we will experiment with the following initilization zero, kaiming and xavier initilization and comprae their results with defaulty initilization. We will modify the previous model by adding weight initilization.\n",
    "\n",
    "In pytorch most initilization functions are implemented in [**torch.nn.init**](http://pytorch.org/docs/0.3.1/nn.html#torch-nn-init). As discussed in tutorial we need to define initilization function that we apply to model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Zero weight initilization\n",
    "\n",
    "In this case we initilize the weight to zero by first defining a function that willinitilize  weight of the nn.Linear module as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_weights_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.fill_(0.0)\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model and apply zero weight initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_zero =  MLP(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the weight init function to the defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_zero.apply(zero_weights_init)\n",
    "print(model_weight_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us check to see if the initial weight is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  param in model_weight_zero.parameters():\n",
    "    print(param.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can now build and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  torch.optim.SGD(model_weight_zero.parameters(), lr=learning_rate, momentum=0.9)\n",
    "total_loss_zero_weight = train(model_weight_zero, optimizer, criterion, 10, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the training loss when zero initilization is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_loss, label=\" default weight\")\n",
    "plt.plot(total_loss_zero_weight, label=\" zero weight\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "1. What can you conclude on the above results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Xavier weight initilization\n",
    "\n",
    "Implemented in [**torch.nn.init.xavier_uniform**](http://pytorch.org/docs/0.3.1/nn.html#torch-nn-init). We will repeat the same procedure as in 2.1 but with xavier weight initilizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_weights_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "        \n",
    "\n",
    "        \n",
    "model_xavier =  MLP(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "model_xavier.apply(xavier_weights_init)\n",
    "print(model_xavier)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  param in model_xavier.parameters():\n",
    "    print(param.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  torch.optim.SGD(model_xavier.parameters(), lr=learning_rate, momentum=0.9)\n",
    "total_loss_xavier = train(model_xavier, optimizer, criterion, 10, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Kaiming weight initilization\n",
    "\n",
    "Implemented in [**torch.nn.init.kaiming_normal()**](http://pytorch.org/docs/0.3.1/nn.html#torch-nn-init). We will repeat the same procedure as in 2.2 but with kaiming weight initilizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_weights_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kaiming =  MLP(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "model_kaiming.apply(kaiming_weights_init)\n",
    "print(model_kaiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_kaiming.parameters():\n",
    "    print(param.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  torch.optim.SGD(model_kaiming.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_kaiming = train(model_kaiming, optimizer, criterion, 10, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let compare the result of the three initilization; default, Xavier and kaiming.\n",
    "\n",
    "**Task**: Plot the the three plot on the same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_loss, label=\"default \")\n",
    "plt.plot(total_loss_xavier, label=\" xavier\")\n",
    "plt.plot(total_loss_kaiming, label=\" kaiming \")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "1. Which initilization techniques is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: \n",
    "Use the best weight initilization to experiments with different learning rate ($0.0001,0.001, 0.01,1$) and different optimisation algorithm such as Adam (`torch.optim.Adam()`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.3 Compare test results\n",
    "Compare accuracy of the four model training with different initilization technoique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_zero, prediction_zero=test(model_weight_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_xavier, prediction_xavier=test(model_xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_kaming, prediction_kaiming=test(model_kaiming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "1. What can you conclude on weight initilization ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Model complexity, overfitting & regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting** occurs when improving the model's training loss (its performance on training data) comes at the expense of its generalisation ability (its performance on unseen test data). Generally it is a symptom of the model complexity increasing to fit the peculiarities (outliers) of the training data too accurately, causing it not to generalize well to new unseen (test) data. Overfitting is usually indicated when:\n",
    "\n",
    "- training & validation loss starts decreasing at different rates,\n",
    "- validation error starts increasing while training error still goes down,\n",
    "- training error reaches 0.\n",
    "\n",
    "**Underfitting** is the opposite: when a model cannot fit the training data well enough (usually a sign to train for longer or add more parameters to the model).\n",
    "\n",
    "We can increase model complexity by adding more layers (i.e. more parameters). We can control or reduce the model complexity of an architecture using a family of techniques called **regularisers**. \n",
    "\n",
    "**Questions**\n",
    "\n",
    "1. Which regularization techniques can be used to control model complexity?\n",
    "2. What is the difference between $L1$ and $L2$ regularizers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Early stopping\n",
    "\n",
    "Neural networks are nonlinear models and can have very complicated optimization landscapes. Stochastic gradient based methods for optimizing these loss functions do not proceed monotonically (i.e. does not just keep going up). Sometimes the loss can go down for a while before it goes up to reach a better part of parameter space later. How do we know when to stop training?\n",
    "\n",
    "\n",
    "**Early stopping** is one technique that helps with this. It is added to the training routine and means that we periodically evaluate the model's performance on the validation set. If the performance on the validation set starts becoming worse we know we have reached the point of overfitting (usually), so it usually makes sense to stop training and not waste any more computations.\n",
    "\n",
    "There are different ways of implementing this early stopping in practise:\n",
    "\n",
    "1. **Basic early stopping**:stop training as soon as the model starts doing worse on validation data.\n",
    "2. **Early stopping with patience**: don't stop training immediately once validation accuracy degrades, but wait for P more epochs, and reset P if the model starts improving again within this timeframe.\n",
    "3. **Eaarly stopping after T epoch**: training for T epochs, and simply selecting the best model based on validation score over the entire T epochs.\n",
    "\n",
    "\n",
    "**Questions**\n",
    "\n",
    "1. Why does early stopping rely on the model performance on validation set and not training set ?\n",
    "2. What are the pros and cons of these different early stopping methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Basic early stopping\n",
    "\n",
    "First let write a function to compare train and validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, optimizer, criterion, num_epochs, device):\n",
    "    \n",
    "    total_train_loss = []\n",
    "    total_val_loss = []\n",
    "    total_train_acc = []\n",
    "    total_val_acc = []\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    \n",
    "    print(\"Start training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        #Train\n",
    "        running_loss = 0\n",
    "        correct  = 0\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        tra_loss=running_loss/len(train_loader.dataset)\n",
    "        tra_cc=100. * correct / len(train_loader.dataset)\n",
    "        \n",
    "        #Validate\n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        correct  = 0\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.view(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "            \n",
    "        val_loss=running_loss/len(test_loader.dataset)\n",
    "        val_acc=100. * correct / len(test_loader.dataset) \n",
    "        \n",
    "        \n",
    "        #save results\n",
    "        total_train_loss.append(tra_loss)\n",
    "        total_val_loss.append(val_loss)\n",
    "        total_train_acc.append(tra_cc)\n",
    "        total_val_acc.append(val_acc)\n",
    "        \n",
    "        if epoch%2==0:\n",
    "            print(\"Epoch: {}, train_loss: {:.4f} , val_loss: {:.4f}, tra_acc: {:.2f}, val_acc: {:.2f}\".format(epoch+1, tra_loss,val_loss, tra_cc, val_acc))\n",
    "       \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(total_train_acc, label=\"Train\")\n",
    "    plt.plot(total_val_acc, label=\"Validation\")\n",
    "    plt.title(\"Accuracy vs Iteration\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Accuracy %\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(total_train_loss, label=\"Train\")\n",
    "    plt.plot(total_val_loss, label=\"Validation\")\n",
    "    plt.title(\"Loss vs Iteration\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_early_stopping =  MLP(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "optimizer =  torch.optim.SGD(model_early_stopping .parameters(), lr=learning_rate, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model(model_early_stopping , optimizer, criterion, 10, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Questions**\n",
    "1. From the above figure does the model overfit or underfit?\n",
    "2. If you were to stop training once the validation accuracy start to decrease, at what epoch (iteration) would you stop?\n",
    "3. Implement the basic early stopping approche by modifying the above code.\n",
    "4. Compare your results with the previous default model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping after T epoch, model saving  and model checkpoint\n",
    "For this lab, we will implement **Early stopping after T epoch**: training for T epochs, and simply selecting the best model based on validation score over the entire T epochs by following the following steps by modifying the previous train function and call valadation(test) function after each epoch. To achieve this we will follow the follwing steps:\n",
    "\n",
    "1. Redifine a train function and we will call it fit function.\n",
    "2. Define a validation function\n",
    "3. Define a model checkpoint and saving function\n",
    "4. Define and call model train function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Define fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, criterion, device, train_loader):\n",
    "    \n",
    "    \n",
    "    \n",
    "    running_loss = 0\n",
    "    correct  = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        #find accuracy\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    tra_loss=running_loss/len(train_loader.dataset)\n",
    "    tra_cc=100. * correct / len(train_loader.dataset)\n",
    "    \n",
    "    return tra_loss, tra_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Define validate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, optimizer, criterion, device, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct  = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        \n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "            \n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "        # statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "            \n",
    "    val_loss=running_loss/len(test_loader.dataset)\n",
    "    val_acc=100. * correct / len(test_loader.dataset) \n",
    "        \n",
    "    return val_loss, val_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Define model save checkpoint function\n",
    "\n",
    "This function will be used to save the best model. Pytorch offer `torch.save()` and `torch.load()` for saving and loading saved models respectively.We will use [shutill](https://docs.python.org/3/library/shutil.html) python library  to save the best model with its associated parameters. Shutill offers a number of high-level operations on files and collections of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def save_checkpoint(state, is_best, model_path):\n",
    "    \n",
    "    torch.save(state, model_path)\n",
    "    \n",
    "    if is_best:\n",
    "        print(\"Saving best model\")\n",
    "        shutil.copyfile(model_path, 'model_best.pth.tar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly we defin a model train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, device, train_loader, test_loader, num_epochs, save_path):\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    best_score = 0\n",
    "    \n",
    "    print(\"Start training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        #fit model\n",
    "        loss_tra, acc_tra = fit(model, optimizer, criterion, device, train_loader)\n",
    "        train_loss.append(loss_tra)\n",
    "        train_acc.append(train_acc)\n",
    "        \n",
    "        #validate model\n",
    "        loss_val, acc_val = validate(model, optimizer, criterion, device,  test_loader)\n",
    "        val_loss.append(loss_val)\n",
    "        val_loss.append(acc_val)\n",
    "        \n",
    "        is_best = acc_val >  best_score\n",
    "        best_score = max(acc_val, best_score)\n",
    "        \n",
    "        save_checkpoint(state={\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': \"MLP\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_score': best_score,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best=is_best,model_path=save_path)\n",
    "        \n",
    "        print(\"Best score is: {:.3f}, current score is: {:.3f}\".format(best_score, acc_val))\n",
    "        \n",
    "        \n",
    "        print(\"Epoch: {}, Train loss: {:.4f} , Valid loss: {:.4f},Train accuracy: {:.2f}, Valid Accuracy: {:.2f}\".format(epoch, loss_tra, \n",
    "                                                                 loss_val, acc_tra, acc_val))\n",
    "        print('----------------------------------------------------------------------------------------------------')\n",
    "    Loss = {\"train\": train_loss, \"val\":val_loss}  \n",
    "    Accuracy =  {\"train\": train_acc, \"val\":val_acc}\n",
    "    \n",
    "    return Loss, Accuracy   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run our model by calling the train_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../tmp/MLP_checkpoint.pth.tar'\n",
    "model_early_stopping =  MLP(input_dim, hidden_dim, output_dim)\n",
    "optimizer =  torch.optim.SGD(model_early_stopping .parameters(), lr=learning_rate, momentum=0.9)\n",
    "loss, acc = train_model(model_early_stopping, optimizer, criterion, device,train_loader, test_loader, 10, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved mode\n",
    "\n",
    "To load pytorch saved modals use `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_modal(saved_model_path, modal, optimizer):\n",
    "    if os.path.isfile(saved_model_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(saved_model_path))\n",
    "        checkpoint = torch.load(saved_model_path)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_score = checkpoint['best_score']\n",
    "        modal.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(saved_model_path, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(saved_model_path))\n",
    "        best_score = 0\n",
    "        start_epoch =0    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "load_saved_modal(save_path, model_early_stopping, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Dropout \n",
    "\n",
    "Dropout[1] is a technique for regularizing neural networks by randomly setting some features to zero during the forward pass. \n",
    "\n",
    "[1] Geoffrey E. Hinton et al, \"Improving neural networks by preventing co-adaptation of feature detectors\", arXiv 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_dropout(input_dim, hidden_dim, output_dim, drop_prob):\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(input_dim,hidden_dim), nn.ReLU(), nn.Dropout(p=drop_prob),\n",
    "    nn.Linear(hidden_dim,hidden_dim),nn.ReLU(), nn.Dropout(p=drop_prob),\n",
    "    nn.Linear(hidden_dim,output_dim)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob = 0.25\n",
    "input_dim = 784 #28X28\n",
    "hidden_dim = 16\n",
    "output_dim = 10\n",
    "model_drop = MLP_dropout(input_dim, hidden_dim, output_dim, drop_prob)\n",
    "print(model_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  torch.optim.SGD(model_drop.parameters(), lr=learning_rate, momentum=0.9)\n",
    "total_loss_drop = train(model_drop , optimizer, criterion, 5, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:\n",
    "1. Run an experiment for different dropout probability $p=0, 0.25, 0.5, 0.75$. \n",
    "2. Compare the total loss for each dropout probability.\n",
    "3. Comments on your results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
