{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PytzMLS2018: Lab 1: Machine learning Fundamentals\n",
    "\n",
    "<center>**Anthony Faustine (sambaiga@gmail.com)**</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary libries and modules we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from ploting import *\n",
    "beatify(fig_width=6)\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Regression Problem\n",
    "\n",
    "**Objective**: In this task we will implement the machine learning algorithm to predict the best house price for a sample house.The model will provide buyers with a rough estimate of what the houses are actually worth. Specifically, we will use data related to housing prices at Boston from [kaggle dataset](https://www.kaggle.com/c/boston-housing/data).\n",
    "\n",
    "The Boston housing data was collected in 1978 and each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts. For the purposes of this project, the following preprocessing steps have been made to the dataset:\n",
    "\n",
    "This data frame contains the following columns:\n",
    "\n",
    "* **crim**: per capita crime rate by town.\n",
    "\n",
    "* **zn**: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "* **indus**: proportion of non-retail business acres per town.\n",
    "\n",
    "* **chas**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "*  **nox**: nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "* **rm**: average number of rooms per dwelling.\n",
    "\n",
    "* **age**: proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "* **dis**: weighted mean of distances to five Boston employment centres.\n",
    "\n",
    "* **rad**: index of accessibility to radial highways.\n",
    "\n",
    "* **tax**: full-value property-tax rate per 10,000USD.\n",
    "\n",
    "* **ptratio**: pupil-teacher ratio by town.\n",
    "\n",
    "* **black**: $1000(B_k - 0.63)^2$ where $B_k$ is the proportion of blacks by town.\n",
    "\n",
    "* **lstat**: lower status of the population (percent).\n",
    "\n",
    "* **medv**: median value of owner-occupied homes in 1000usd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load dataset\n",
    "\n",
    "We will use panda to load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=  pd.read_csv(\"../data/house/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Questions**\n",
    "\n",
    "1. What is the target variable ?\n",
    "2. What is the total numbers of sample in this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data visualization and feature engeeniering¶\n",
    "\n",
    "In this  section  you will make a cursory investigation about the Boston housing data and provide your observations. Familiarizing yourself with the data through an explorative process is a fundamental practice to help you better understand and justify your results. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Missing Values Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: \n",
    "1. Check if the data contain missing values\n",
    "2. How can you address missing values in your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Descriptive Statistics\n",
    "Calculate the following descriptive statistics: the minimum, maximum, mean, median, and standard deviation of **medv**.\n",
    "Store each calculation in their respective variable.\n",
    "\n",
    "These statistics will be extremely important later on to analyze various prediction results from the constructed model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Minimum price of the data\n",
    "minimum_price = data.medv.min()\n",
    "\n",
    "# TODO: Maximum price of the data\n",
    "maximum_price = data.medv.max()\n",
    "\n",
    "# TODO: Mean price of the data\n",
    "mean_price = data.medv.mean()\n",
    "\n",
    "# TODO: Median price of the data\n",
    "median_price = data.medv.median()\n",
    "\n",
    "# TODO: Standard deviation of prices of the data\n",
    "std_price = data.medv.std()\n",
    "\n",
    "# Show the calculated statistics\n",
    "print (\"Statistics for Boston housing dataset:\\n\")\n",
    "print (\"Minimum price: {:.2f}\".format(minimum_price))\n",
    "print (\"Maximum price: {:.2f}\".format(maximum_price))\n",
    "print (\"Mean price: {:.2f}\".format(mean_price))\n",
    "print (\"Median price {:.2f}\".format(median_price))\n",
    "print (\"Standard deviation of prices: {:.2f}\".format(std_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we could obtain the descriptive of our dataset using the *describe* pandas command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our specific medv column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medv'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=8)\n",
    "sns.set(font_scale=1)  \n",
    "sns.heatmap(data.corr(),annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = data.corr()['medv'].sort_values(axis=0,ascending=False).iloc[1:]\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "1. Which features are strongly correlated with **medv** variable ?.\n",
    "2. Using your intuition, for each of the 13 features above, do you think that an increase in the value of that feature would lead to an increase in the value of **'medv'** or a decrease in the value of **'medv'**? Justify your answer for each.\n",
    "3. Which features are strongly correlated to each other?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "1. Plot the scatter plot between target variable and features varibles.\n",
    "2. Is there any linear relationship between the target varible and features variables?\n",
    "3. Which features have strong linear relationship with target varibale. How does this results compare with the previous correlation results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Automatic Feature Selection\n",
    "\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.\n",
    "\n",
    "Having too many irrelevant features in your data can decrease the accuracy of the models. \n",
    "\n",
    "Three benefits of performing feature selection before modeling your data are:\n",
    "\n",
    "* Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "* Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "* Reduces Training Time: Less data means that algorithms train faster.\n",
    "\n",
    "You can use the following approach\n",
    "\n",
    "- Univariate statistics: Check statisticall significance relation between feature and target\n",
    "- Model-base selection:\n",
    "- Iterative selection:\n",
    "\n",
    "\n",
    "**Univariate statistics** \n",
    "- Check statisticall significance relation between feature and target.\n",
    "- select the one with high confidence\n",
    "\n",
    "Advantage: Very fast to compute, doesnt require building models\n",
    "\n",
    "Disadvantage: Independent of the model\n",
    "\n",
    "** Model-based Feature Selection**\n",
    "- Use a supervised machine learning model to judge the importance of each feature.\n",
    "\n",
    "Advantages: Consider all features at once.\n",
    "\n",
    "**Iterative Feature Selection**\n",
    "A series of models are built with varying number of features. Implemented in Sklearn as [Recursive feature elimination (RFE)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use  model - based feature Selection using `RandomForestRegressor` from `sklearn.ensemble`. Random forests are among the most popular machine learning methods thanks to their relatively good accuracy, robustness and ease of use. They also provide two straightforward methods for feature selection: mean decrease impurity and mean decrease accuracy as discussed in [this blog post](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Mean decrease impurity\n",
    "Random forest consists of a number of decision trees. Every node in the decision trees is a condition on a single feature, designed to split the dataset into two so that similar response values end up in the same set. The measure based on which the (locally) optimal condition is chosen is called impurity. For classification, it is typically either Gini impurity or information gain/entropy and for regression trees it is variance. Thus when training a tree, it can be computed how much each feature decreases the weighted impurity in a tree. For a forest, the impurity decrease from each feature can be averaged and the features are ranked according to this measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Feature and Target\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat']\n",
    "\n",
    "X = data[feature]\n",
    "y = data.medv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define a model\n",
    "rforest = RandomForestRegressor()\n",
    "# Fit the model\n",
    "rforest.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the important features\n",
    "beatify(fig_width=8)\n",
    "imp_feat_rf = pd.Series(rforest.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "imp_feat_rf.plot(kind='bar', title='Feature Importance with Random Forest', color='C0')\n",
    "plt.ylabel('Feature Importance values')\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question**\n",
    "1. From the figure above what are the best features that strongly explain the target variable?\n",
    "2. How does this result compare with correlation results from the previous  section?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Mean decrease score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "def feature_select(model,names, metric, X, Y):\n",
    "    \n",
    "    rs = ShuffleSplit(n_splits=len(X), test_size=.1, random_state=22)\n",
    "    scores = defaultdict(list)\n",
    "    \n",
    "    for train_idx, test_idx in rs.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        acc= metric(Y_pred, Y_test)\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            X_t = X_test.copy()\n",
    "            np.random.shuffle(X_t[:, i])\n",
    "            shuff_acc = metric(model.predict(X_t), Y_test)\n",
    "            \n",
    "            scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "    print (\"Features sorted by their score:\")\n",
    "    print (sorted([(round(np.mean(score), 3), feat) for\n",
    "              feat, score in scores.items()], reverse=True))\n",
    "    \n",
    "    results = sorted([(np.around(np.mean(score), decimals=3), feat) for\n",
    "              feat, score in scores.items()], reverse=True)\n",
    "    \n",
    "    plt.bar(range(len(results)), [val[0] for val in results], align='center')\n",
    "    plt.xticks(range(len(results)), [val[1] for val in results])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.ylabel(\"Score ($\\%$)\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = feature_select(rforest, feature, r2_score, X.as_matrix(), y.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question**\n",
    "1. From the figure above what are the best features that strongly explain the target variable?\n",
    "2. How does this result compare with  the previous  approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Model - based feature Selection : Using **SelectFromModel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "select = SelectFromModel(RandomForestRegressor() , threshold=\"median\")\n",
    "select.fit(X,y)\n",
    "X_features = select.transform(X)\n",
    "print('Original features', X.shape)\n",
    "print('Selected features', X_features.shape)\n",
    "for feature_list_index in select.get_support(indices=True):\n",
    "    print(feature[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question**\n",
    "1. How does this result compare with above and  correlation results from the previous  sections?\n",
    "2. Which features will you use to develop a predictive model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Develop predictive models\n",
    "\n",
    "In this section you will develop the tools and techniques necessary for a model to make a prediction. However it is important to define  accurate evaluations of each model's performance by quantifying its performance over training and testing. This is typically done using some type of performance metric, whether it is through calculating some type of error, the goodness of fit, or some other useful measurement.\n",
    "\n",
    "In this part will use the coefficient of determination, **R2**, to quantify  model's performance. The coefficient of determination is  useful statistic in regression analysis and  describes how \"good\" that model is at making predictions.\n",
    "\n",
    "The values for R2 range from 0 to 1, which captures the percentage of squared correlation between the predicted and actual values of the target variable. A model with an R2 of 0 is no better than a model that always predicts the mean of the target variable, whereas a model with an R2 of 1 perfectly predicts the target variable. Any value between 0 and 1 indicates what percentage of the target variable, using this model, can be explained by the features.\n",
    "\n",
    "Hint: The R2 score is the proportion of the variance in the dependent variable that is predictable from the independent variable. In other words:\n",
    "\n",
    "- R2 score of 0 means that the dependent variable cannot be predicted from the independent variable.\n",
    "- R2 score of 1 means the dependent variable can be predicted from the independent variable.\n",
    "- R2 score between 0 and 1 indicates the extent to which the dependent variable is predictable.\n",
    "- R2 score of 0.40 means that 40 percent of the variance in Y is predictable from X.\n",
    "\n",
    "A model can be given a negative R2 as well, which indicates that the model is arbitrarily worse than one that always predicts the mean of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def metric(y_true, y_pred):\n",
    "    \n",
    "    score = r2_score(y_true, y_pred)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Shuffle and Split Data\n",
    "\n",
    "In this stage you will take  dataset and split the data into training and testing subsets. Typically, the data is also shuffled into a random order when creating the training and testing subsets to remove any bias in the ordering of the dataset. You will use the following features 'rm', 'lstat', 'ptratio'.\n",
    "\n",
    "To achieve this:\n",
    "- Use `train_test_split from sklearn.model_selection` to shuffle and split the features and prices data into training and testing sets.\n",
    "- Split the data into 80% training and 20% testing.\n",
    "- Set the random_state for train_test_split to a value of your choice. This ensures results are consistent.\n",
    "- Assign the train and testing splits to X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['crim', 'nox', 'rm', 'age', 'dis', 'black', 'lstat']\n",
    "X = data[features]\n",
    "y = data.medv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training: Features: {0},  Target: {1}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test: Features: {0},  Target: {1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "    1. What is the benefit to splitting a dataset into some ratio of training and testing subsets for a learning algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Model selection\n",
    "\n",
    "Scikit-learn offer several regression models we can use for this problem. We will compare the following six regression model and find the best model.\n",
    "\n",
    "- Linear Regression\n",
    "- Random Forest regressor\n",
    "- Decision tree regressor\n",
    "- BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_fit(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    rf = RandomForestRegressor()\n",
    "    dt = DecisionTreeRegressor()\n",
    "    ls = Lasso()\n",
    "    rdg = Ridge()\n",
    "    brdg = BayesianRidge()\n",
    "    \n",
    "    models = {\"LR\":reg, \"RF\":rf, \"DT\":dt, \"LASSO\":ls, \"RG\":rdg, \"BayesRG\": brdg}\n",
    "    results = {}\n",
    "    \n",
    "    for (key,model) in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        results[key]=metric(y_test, y_pred)\n",
    "        \n",
    "    return results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = regression_fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question**\n",
    "1. Which models show better performance ?\n",
    "2. Repeat the above experiments using all available features and compare your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Cross validation\n",
    "\n",
    "Evaluating model perfomance using train/test split approach is very fast and  ideal for large datasets. It is recommended to use use this approach when the algorithm you are investigating is slow to train. However in most cases train/test split provides a high variance estimate since changing which observations happen to be in the testing set can significantly change testing accuracy. Testing accuracy can change a lot depending on a which observation happen to be in the testing set\n",
    "\n",
    "Cross validation is a statistical method for evaluating how well a given algorithm will generalize when trained on a specific data set. It is an approach that you can use to estimate the performance of a machine learning algorithm with less variance than a single train-test set split. In cross validation we split the data repetedely and train a multiple models.\n",
    "\n",
    "\n",
    "**Advantages of cross-validation**:\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data\n",
    "   - This is because every observation is used for both training and testing\n",
    "\n",
    "\n",
    "\n",
    "**Types of cross-validation**\n",
    "\n",
    "- K-fold cross validation\n",
    "- Startified K-fold cross validation\n",
    "- Leave-one-out cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def regression_cross_validation(X, y, score='r2'):\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    rf = RandomForestRegressor()\n",
    "    dt = DecisionTreeRegressor()\n",
    "    ls = Lasso()\n",
    "    rdg = Ridge()\n",
    "    brdg = BayesianRidge()\n",
    "    \n",
    "    models = {\"LR\":reg, \"RF\":rf, \"DT\":dt, \"LASSO\":ls, \"RG\":rdg, \"BayesRG\": brdg}\n",
    "    results = {}\n",
    "    \n",
    "    kfold=KFold(n_splits=5, random_state=40, shuffle=True)\n",
    "    \n",
    "    for (key,model) in models.items():\n",
    "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring=score)\n",
    "        results[key]=cv_results.mean()\n",
    "        \n",
    "    return results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = regression_cross_validation(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question**\n",
    "1. Which models show better performance ?\n",
    "2. How does your results compare with the previsous results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Classification: Diabetes Prediction with Pima data\n",
    "\n",
    "The objective:To diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the [PIMA dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database). The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.DataFrame({\n",
    "    \"Attributes\": [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \n",
    "              \"SkinThickness\", \"Insulin\", \"BMI\", \n",
    "              \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"],\n",
    "    \"Explanation\": [\"Number of times pregnant\", \n",
    "                 \"Plasma glucose concentration a 2 hours in an oral glucose tolerance test\", \n",
    "                 \"Diastolic blood pressure (mm Hg)\", \n",
    "                \"Triceps skin fold thickness (mm)\", \n",
    "                 \"2-Hour serum insulin (mu U/ml)\",\n",
    "                 \"Body mass index (weight in kg/(height in m)^2)\", \n",
    "              \"Diabetes pedigree function\"\n",
    "                 ,\"years\",\n",
    "                   \"Diabetes or not\"]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 1 Load Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/pima/diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Check and handle missing data if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=6)\n",
    "sns.set(font_scale=1) \n",
    "sns.heatmap(data.corr(),annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice high positive correlations between Age and Pregnancies, which is logical. Also between BMI and Skin thickness, Glucose and Insulin as well as Glucose and Outcome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = data.corr()['Outcome'].sort_values(axis=0,ascending=False).iloc[1:]\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of varible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=6)\n",
    "data.hist();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "1. Briefly explain the distribution of each variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"Outcome\"])\n",
    "print(\"Number of negative outcomes\",np.count_nonzero(data[\"Outcome\"]))\n",
    "print(\"Number of positive outcomes\",len(data[\"Outcome\"])-np.count_nonzero(data[\"Outcome\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nearly twice as many negative outcomes as there is positive in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregnancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=2)\n",
    "sns.distplot(data[\"Pregnancies\"]);\n",
    "data[\"Pregnancies\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution is positively skewed. Looks exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Glucose\"]);\n",
    "data[\"Glucose\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again positively skewed with outliers to the left, resembles the normal distribution. Those zeros might be missing values, a Glucose concentration of 0 is unrealistic. Lets mark them with NaN instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Glucose\"] = data[\"Glucose\"].replace(0, np.nan)\n",
    "data[\"Glucose\"].isnull().sum() # Number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insulin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Insulin\"]);\n",
    "data[\"Insulin\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have invalid zero values, replace with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Insulin\"] = data[\"Insulin\"].replace(0, np.nan)\n",
    "data[\"Insulin\"].isnull().sum() # Number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"BMI\"]);\n",
    "data[\"BMI\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"BMI\"] = data[\"BMI\"].replace(0, np.nan)\n",
    "data[\"BMI\"].isnull().sum() # Number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DiabetesPedigreeFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"DiabetesPedigreeFunction\"]);\n",
    "data[\"DiabetesPedigreeFunction\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution is positively skewed, and subject to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Age\"]);\n",
    "data[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution is positively skewed. Looks again exponential-ish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Divide the data\n",
    "\n",
    "Now lets divide the data in to a seperate test set and a train set which we will train our models on. Note that we do this before the attribute selection so that any bias is not introduced. The test set should represent future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let check for missing data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insulin column has many missing values we can drop this column and fill the missing column of BMI and Glucose with median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Insulin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill missing value \n",
    "data['Glucose'].fillna(data['Glucose'].median(), inplace=True)\n",
    "data['BMI'].fillna(data['BMI'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "targets = data[\"Outcome\"]\n",
    "features = data.drop([\"Outcome\"], axis = 1)\n",
    "cols = data.columns\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, test_size=0.1, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata = pd.DataFrame(np.hstack((x_train, y_train[:,np.newaxis])), columns = data.columns)\n",
    "testdata = pd.DataFrame(np.hstack((x_test, y_test[:,np.newaxis])), columns = data.columns)\n",
    "testdata.to_csv('../data/pima/test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the importance of the attributes features for predicting the outcome. We might be able to remove attributes with a lot of missing values and hence increase our sample-size. We will use two different methods for the selection, one unsupervised attribute extraction that changes the attributes and one supervised attribute selection that don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate features and targets\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "train_y = trainingdata[\"Outcome\"]\n",
    "train_x = trainingdata[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Z-Standardization to features\n",
    "We use `StandardScaler` from `sklearn.preprocessing` for details refer to this [link](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler). \n",
    "Important method:\n",
    "\n",
    "- `fit()`:\tCompute the mean and std to be used for later scaling.\n",
    "- `fit_transform()` :\tFit to data, then transform it.\n",
    "- `get_params()`\t:Get parameters for this estimator.\n",
    "- `inverse_transform()`:\tScale back the data to the original representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "z_scaler = StandardScaler()\n",
    "z_scaler.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_scaled = z_scaler.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Alternatively you could implement this yourself as follows:\n",
    "train_x_ = train_x.apply(lambda x: (x - np.mean(x))/np.std(x)) # Z Standardization\n",
    "train_x_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the mean decrease score feasture selection as explained in section 1.2.2 to select best features for this problem. Since this is classification problem, we will use accuracy as the metric score and logistic regression as a classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "results=feature_select(lr, features, accuracy_score, train_x_scaled, train_y.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you choose the best model for your problem?. When you work on a machine learning project, you often end up with multiple good models to choose from. Since our dataset is small the best way to approach it is probably by using cross validation. Lets establish a baseline for the problem by using cross validation and a few classification models. If we use k-fold cross validation since our dataset is quite small a splitting of our data into to few folds could introduce a substantial bias. On the other hand if we chose k to large we will have a lot of variance. With the small data-set in the back of our head we chose k to be moderately large, 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiers(X, y, score='f1'):\n",
    "    \n",
    "    knn     =  KNeighborsClassifier()\n",
    "    svm     = SVC()\n",
    "    gnb     =  GaussianNB()\n",
    "    log     =  LogisticRegression()\n",
    "    dTree   =  tree.DecisionTreeClassifier()\n",
    "    rForest =  RandomForestClassifier()\n",
    "    \n",
    "    \n",
    "    models = {\"LG\":log, \"RF\":rForest, \"DT\":dTree, \"NB\":gnb, \"SVM\":svm, \"KNN\":knn}\n",
    "    results = {}\n",
    "    skfold = StratifiedKFold(n_splits=18)\n",
    "\n",
    "    \n",
    "    for (key,model) in models.items():\n",
    "        cv_results = cross_val_score(model, X, y, cv=skfold, scoring=score)\n",
    "        results[key]=cv_results.mean()\n",
    "        msg = \"{0}: {1}\" .format(key, cv_results.mean())\n",
    "        print(msg)\n",
    "        \n",
    "    return results   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =classifiers(train_x_scaled, train_y.as_matrix(), score='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Questions**:\n",
    "    1. What are the three best models for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.2 Hyper-parameter Selection\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within model. In scikit-learn they are passed as arguments to the constructor of the model classes. Specifically, to find the names and current values for all parameters for a given model, use: `model.get_params()`.\n",
    "\n",
    "It is possible to automatically find good values for the hyper-parameters by using tools such as grid search and cross validation.In machine learning, these tasks are commonly done at the same time in data pipelines. Cross validation is the process of training learners using one set of data and testing it using a different set. Parameter tuning is the process to selecting the values for a model’s parameters that maximize the accuracy of the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "** Question**\n",
    "1. List all hyper parameter for the best three models from previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log     =  LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal parameter for [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def get_best_parameter(model, parameters, X, y):\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits=18)\n",
    "    clf = GridSearchCV(model, parameters, cv=skfold)\n",
    "    clf.fit(X, y)\n",
    "   \n",
    "    print(\"Training best score: %.2f\" %clf.best_score_)\n",
    "    print(\"Best parameter: {}\" .format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_logreg = {'C':  [0.001, 0.01, 0.1, 1, 10],\n",
    "                           'penalty':['l1', 'l2'], \n",
    "                           }\n",
    "log = LogisticRegression()\n",
    "get_best_parameter(log, parameters_logreg, train_x_scaled, train_y.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal parameter for [support vector machine](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = [ 'linear', 'poly', 'rbf', 'sigmoid']\n",
    "parameters_svm = {'C': Cs, 'gamma' : gammas, 'kernel': kernels}\n",
    "svm     = SVC()\n",
    "get_best_parameter(svm, parameters_svm, train_x_scaled, train_y.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task \n",
    "1. What are the optimal hyper-parameters for the two selected models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Udacity project](https://github.com/baninaveen/Predicting_Boston_House_Pricing-/blob/master/boston_housing_price.ipynb)\n",
    "- [PIMA](https://github.com/Tranhd/Diabetes-Classification/blob/master/Exploratory%20Analysis.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
